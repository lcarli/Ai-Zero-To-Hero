/* ============================================
   AIFORALL V2 ‚Äî LLM Demo
   Pipeline visualization, text generation,
   temperature/topK playground, model comparison
   ============================================ */

const LLMDemo = (() => {

  let generationInterval = null;

  /** Render full module */
  function render() {
    const state = Progress.getState();
    const mState = state.modules.llm || {};

    return `
      <div class="page module-page">
        <section class="section">
          <div class="container">
            <a href="#/" class="btn btn-ghost mb-8">‚Üê Voltar √† trilha</a>

            <div class="module-header">
              <span style="font-size: 3rem;">ü§ñ</span>
              <div>
                <h1>Large Language Models</h1>
                <p>O pipeline completo: de texto a previs√£o do pr√≥ximo token</p>
              </div>
            </div>

            <div class="tab-bar">
              <button class="tab active" data-tab="learn">üìñ Aprender</button>
              <button class="tab" data-tab="pipeline">üîÑ Pipeline</button>
              <button class="tab" data-tab="generate">‚ú® Gerar Texto</button>
              <button class="tab" data-tab="playground">üéõÔ∏è Playground</button>
              <button class="tab" data-tab="models">üìä Modelos</button>
              <button class="tab" data-tab="quiz">üìù Quiz</button>
            </div>

            <div id="tab-learn" class="tab-content active">${renderLearnTab()}</div>
            <div id="tab-pipeline" class="tab-content hidden">${renderPipelineTab()}</div>
            <div id="tab-generate" class="tab-content hidden">${renderGenerateTab()}</div>
            <div id="tab-playground" class="tab-content hidden">${renderPlaygroundTab()}</div>
            <div id="tab-models" class="tab-content hidden">${renderModelsTab()}</div>
            <div id="tab-quiz" class="tab-content hidden">${renderQuizTab(mState)}</div>
          </div>
        </section>
      </div>
    `;
  }

  /* =================== Tab Renders =================== */

  function renderLearnTab() {
    return `
      <div class="learn-section">
        <div class="card-flat mb-8">
          <h3>ü§ñ O que √© um LLM?</h3>
          <p>Um <strong>Large Language Model</strong> √© um modelo de IA treinado em enormes quantidades de texto 
          para prever o <em>pr√≥ximo token</em>. Apesar da aparente simplicidade, essa tarefa faz o modelo aprender 
          gram√°tica, fatos, racioc√≠nio e at√© c√≥digo.</p>
        </div>

        <div class="card-flat mb-8">
          <h3>üîÑ O Pipeline</h3>
          <div class="llm-pipeline-flow">
            ${['Texto', 'Tokeniza√ß√£o', 'Embedding\n+ Posi√ß√£o', 'N√ó Transformer\nBlocks', 'Linear\n+ Softmax', 'Pr√≥ximo\nToken'].map((s, i, arr) => `
              <div class="pipeline-node">
                <span>${['üìù', 'üß©', 'üìê', 'üîÑ', 'üìä', 'üéØ'][i]}</span>
                <span class="text-xs">${s.replace('\n', '<br>')}</span>
              </div>
              ${i < arr.length - 1 ? '<span class="pipeline-arrow">‚Üí</span>' : ''}
            `).join('')}
          </div>
        </div>

        <div class="grid grid-cols-2 gap-6 mb-8">
          <div class="card-flat">
            <h4>üß© 1. Tokeniza√ß√£o</h4>
            <p class="text-sm">O texto √© dividido em subpalavras (tokens) usando BPE. 
            Cada token recebe um ID num√©rico do vocabul√°rio (~50K-100K tokens).</p>
          </div>
          <div class="card-flat">
            <h4>üìê 2. Embedding + Posi√ß√£o</h4>
            <p class="text-sm">Cada token ID √© convertido em um vetor denso (ex: 12.288 dimens√µes no GPT-3). 
            Positional Encoding √© adicionado para saber a ordem.</p>
          </div>
          <div class="card-flat">
            <h4>üîÑ 3. Transformer Blocks</h4>
            <p class="text-sm">A sequ√™ncia passa por N camadas (96 no GPT-3), cada uma com: 
            Self-Attention ‚Üí Add & Norm ‚Üí Feed-Forward ‚Üí Add & Norm.</p>
          </div>
          <div class="card-flat">
            <h4>üìä 4. Linear + Softmax</h4>
            <p class="text-sm">O output do √∫ltimo token √© projetado para o vocabul√°rio inteiro. 
            Softmax transforma em probabilidades ‚Üí amostragem do pr√≥ximo token.</p>
          </div>
        </div>

        <div class="card-flat mb-8">
          <h3>üå°Ô∏è Temperature & Sampling</h3>
          <p><strong>Temperature</strong> controla a "criatividade":</p>
          <ul class="mt-2">
            <li><strong>Temp = 0</strong> ‚Üí sempre escolhe o mais prov√°vel (determin√≠stico, repetitivo)</li>
            <li><strong>Temp = 0.7</strong> ‚Üí bom equil√≠brio (criativo mas coerente)</li>
            <li><strong>Temp = 1.5+</strong> ‚Üí muito aleat√≥rio (pode ficar incoerente)</li>
          </ul>
          <p class="mt-4"><strong>Top-K</strong>: considera apenas os K tokens mais prov√°veis.</p>
          <p><strong>Top-P (Nucleus)</strong>: considera tokens at√© acumular P% de probabilidade.</p>
        </div>

        <div class="card-flat">
          <h3>üîÅ Autoregressive Generation</h3>
          <p>O modelo gera <strong>um token por vez</strong>, sempre alimentando sua pr√≥pria sa√≠da de volta como entrada. 
          Cada gera√ß√£o requer passar pelo pipeline inteiro novamente.</p>
          <p class="text-sm text-muted mt-2">√â por isso que LLMs s√£o "lentos" para gerar ‚Äî cada token precisa de uma passada completa pela rede.</p>
        </div>
      </div>
    `;
  }

  function renderPipelineTab() {
    return `
      <div class="pipeline-section">
        <div class="card-flat mb-4">
          <h3>üîÑ Visualize o Pipeline</h3>
          <p class="text-sm text-muted">Digite um texto e veja cada est√°gio do processamento.</p>
          <div class="flex gap-4 items-center mt-4">
            <input id="pipeline-input" class="input" value="The cat sat on" 
              placeholder="Digite um texto..." style="flex:1;min-width:200px;">
            <button class="btn btn-primary" id="pipeline-run-btn">Processar</button>
          </div>
        </div>
        <div id="pipeline-container" class="mt-4"></div>
      </div>
    `;
  }

  function renderGenerateTab() {
    const aiReady = typeof FoundryService !== 'undefined' && FoundryService.isConfigured();
    return `
      <div class="generate-section">
        <div class="card-flat mb-4">
          <h3>‚ú® Gera√ß√£o de Texto</h3>
          <p class="text-sm text-muted">Veja gera√ß√£o token a token (simulada) ou use um modelo real.</p>
          <div class="flex gap-4 items-center mt-4 flex-wrap">
            <input id="gen-input" class="input" value="The cat" 
              placeholder="Prompt..." style="flex:1;min-width:200px;">
            <div class="flex gap-2 items-center">
              <label class="text-sm">Tokens:</label>
              <input id="gen-count" type="number" class="input" value="6" min="1" max="20" style="width:60px;">
            </div>
            <button class="btn btn-primary" id="gen-run-btn">‚ñ∂Ô∏è Gerar (Simulado)</button>
            <button class="btn ${aiReady ? 'btn-accent' : 'btn-ghost'}" id="gen-ai-btn" ${!aiReady ? 'disabled title="Configure a API em ‚öôÔ∏è Configura√ß√µes"' : ''}>‚ö° Gerar com IA Real</button>
            <button class="btn btn-ghost" id="gen-stop-btn" disabled>‚èπÔ∏è Parar</button>
          </div>
          ${!aiReady ? '<p class="text-xs text-muted mt-2">üí° <a href="#/settings" style="color:var(--primary);">Configure uma API</a> para habilitar gera√ß√£o com IA real.</p>' : ''}
        </div>
        <div id="gen-output" class="mt-4"></div>
        <div id="gen-steps" class="mt-4"></div>
      </div>
    `;
  }

  function renderPlaygroundTab() {
    return `
      <div class="playground-section">
        <div class="card-flat mb-4">
          <h3>üéõÔ∏è Playground de Sampling</h3>
          <p class="text-sm text-muted">Ajuste Temperature e Top-K para ver como afetam a distribui√ß√£o de probabilidade.</p>
        </div>

        <div class="grid grid-cols-2 gap-6">
          <div class="card-flat">
            <h4>Controles</h4>
            <div class="mt-4">
              <label class="text-sm font-bold">Palavra contexto:</label>
              <input id="pg-word" class="input mt-2" value="the" placeholder="Ex: the, cat, is...">
            </div>
            <div class="mt-4">
              <div class="flex items-center justify-between">
                <label class="text-sm font-bold">üå°Ô∏è Temperature: <span id="pg-temp-val">1.0</span></label>
              </div>
              <input id="pg-temp" type="range" min="0" max="2" step="0.1" value="1.0" class="slider mt-2">
              <div class="flex justify-between text-xs text-muted">
                <span>0 (Greedy)</span><span>1.0 (Normal)</span><span>2.0 (Random)</span>
              </div>
            </div>
            <div class="mt-4">
              <div class="flex items-center justify-between">
                <label class="text-sm font-bold">üéØ Top-K: <span id="pg-topk-val">5</span></label>
              </div>
              <input id="pg-topk" type="range" min="1" max="10" step="1" value="5" class="slider mt-2">
              <div class="flex justify-between text-xs text-muted">
                <span>1 (s√≥ o melhor)</span><span>10 (mais op√ß√µes)</span>
              </div>
            </div>
            <button class="btn btn-primary mt-4" id="pg-run-btn" style="width:100%;">Atualizar distribui√ß√£o</button>
          </div>
          <div class="card-flat">
            <h4>Distribui√ß√£o de Probabilidade</h4>
            <div id="pg-chart" class="mt-4"></div>
          </div>
        </div>
      </div>
    `;
  }

  function renderModelsTab() {
    return `
      <div class="models-section">
        <div class="card-flat mb-4">
          <h3>üìä Compara√ß√£o de Modelos</h3>
          <p class="text-sm text-muted">Veja como os LLMs evolu√≠ram ao longo dos anos.</p>
        </div>

        <div style="overflow-x:auto;">
          <table class="attn-step-table">
            <thead>
              <tr>
                <th>Modelo</th>
                <th>Par√¢metros</th>
                <th>Layers</th>
                <th>d_model</th>
                <th>Heads</th>
                <th>Vocab</th>
                <th>Ano</th>
              </tr>
            </thead>
            <tbody>
              ${LLMEngine.MODEL_SIZES.map(m => `
                <tr>
                  <td class="font-bold">${m.name}</td>
                  <td><span class="badge badge-primary">${m.params}</span></td>
                  <td>${m.layers}</td>
                  <td>${m.dModel}</td>
                  <td>${m.heads}</td>
                  <td>${m.vocab}</td>
                  <td>${m.year}</td>
                </tr>
              `).join('')}
            </tbody>
          </table>
        </div>

        <div class="card-flat mt-6">
          <h4>üìà Escala de Par√¢metros (visual)</h4>
          <div class="mt-4">
            ${[
              { name: 'GPT-2', val: 1.5, color: '#6366f1' },
              { name: 'LLaMA 2 (70B)', val: 70, color: '#06b6d4' },
              { name: 'GPT-3 (175B)', val: 175, color: '#f59e0b' },
              { name: 'GPT-4 (~1.8T)', val: 1800, color: '#ef4444' },
            ].map(m => {
              const pct = Math.min((Math.log10(m.val) / Math.log10(1800)) * 100, 100);
              return `
              <div class="flex items-center gap-3 mb-3">
                <span class="text-sm font-bold" style="width:120px;">${m.name}</span>
                <div class="progress-bar" style="flex:1;height:14px;">
                  <div class="progress-fill" style="width:${pct}%;background:${m.color};"></div>
                </div>
                <span class="text-xs font-mono" style="width:60px;">${m.val >= 1000 ? (m.val / 1000).toFixed(1) + 'T' : m.val + 'B'}</span>
              </div>`;
            }).join('')}
          </div>
          <p class="text-xs text-muted mt-2">Escala logar√≠tmica. GPT-4 √© ~1200√ó maior que GPT-2.</p>
        </div>
      </div>
    `;
  }

  function renderQuizTab(mState) {
    return `
      <div class="quiz-section">
        <div class="card-flat">
          <div class="flex items-center justify-between mb-4">
            <h3 style="margin:0">üìù Quiz ‚Äî LLM</h3>
            <div class="module-stars" style="font-size: 1.5rem;">
              ${[1, 2, 3].map(s => `<span class="star ${s <= (mState.stars || 0) ? 'earned' : ''}">‚òÖ</span>`).join('')}
            </div>
          </div>
          <p>Teste seus conhecimentos sobre Large Language Models!</p>
          <button class="btn btn-primary btn-lg mt-4" id="start-quiz-btn">Come√ßar Quiz</button>
        </div>
        <div id="quiz-container" class="hidden mt-6"></div>
        <div id="quiz-results" class="hidden mt-6"></div>
      </div>
    `;
  }

  /* =================== Quiz =================== */
  const QUIZ_QUESTIONS = [
    {
      question: 'Qual √© a tarefa fundamental de treinamento de um LLM?',
      options: [
        'Classificar textos em categorias',
        'Prever o pr√≥ximo token dada uma sequ√™ncia',
        'Traduzir entre idiomas',
        'Encontrar erros gramaticais no texto',
      ],
      correct: 1,
      explanation: 'LLMs s√£o treinados para prever o pr√≥ximo token (next-token prediction). Apesar de simples, essa tarefa faz o modelo aprender linguagem, fatos, racioc√≠nio e muito mais.',
    },
    {
      question: 'O que acontece quando a Temperature √© 0?',
      options: [
        'O modelo gera texto aleat√≥rio',
        'O modelo sempre escolhe o token mais prov√°vel (greedy)',
        'O modelo para de funcionar',
        'O modelo gera respostas mais criativas',
      ],
      correct: 1,
      explanation: 'Com Temperature = 0, o modelo sempre escolhe o token com maior probabilidade. Isso d√° respostas determin√≠sticas mas pode ser repetitivo.',
    },
    {
      question: 'Quantos par√¢metros tem o GPT-3?',
      options: [
        '1.5 bilh√£o',
        '13 bilh√µes',
        '175 bilh√µes',
        '1 trilh√£o',
      ],
      correct: 2,
      explanation: 'O GPT-3 tem 175 bilh√µes de par√¢metros, distribu√≠dos em 96 camadas de transformer com 96 cabe√ßas de aten√ß√£o cada.',
    },
    {
      question: 'O que √© "autoregressive generation"?',
      options: [
        'Gerar todo o texto de uma vez',
        'Gerar um token por vez, usando a sa√≠da anterior como entrada',
        'Treinar o modelo automaticamente',
        'Fazer o modelo corrigir seus pr√≥prios erros',
      ],
      correct: 1,
      explanation: 'Gera√ß√£o autorregressiva significa gerar um token por vez, sempre adicionando o token gerado de volta √† entrada para prever o pr√≥ximo. Por isso LLMs parecem "digitar" a resposta.',
    },
    {
      question: 'O que o Top-K sampling faz?',
      options: [
        'Seleciona os K textos mais longos',
        'Limita a amostragem aos K tokens mais prov√°veis',
        'Divide o texto em K partes',
        'Treina K modelos diferentes',
      ],
      correct: 1,
      explanation: 'Top-K filtra o vocabul√°rio para considerar apenas os K tokens com maior probabilidade, redistribuindo a massa probabil√≠stica entre eles. Evita tokens raros/incoerentes.',
    },
  ];

  let quizState = { current: 0, answers: [], startTime: 0 };

  /* =================== Interactions =================== */

  function initInteractions() {
    // Pipeline
    document.getElementById('pipeline-run-btn')?.addEventListener('click', runPipeline);

    // Generate
    document.getElementById('gen-run-btn')?.addEventListener('click', runGeneration);
    document.getElementById('gen-ai-btn')?.addEventListener('click', runAIGeneration);
    document.getElementById('gen-stop-btn')?.addEventListener('click', stopGeneration);

    // Playground
    document.getElementById('pg-run-btn')?.addEventListener('click', updatePlayground);
    document.getElementById('pg-temp')?.addEventListener('input', (e) => {
      document.getElementById('pg-temp-val').textContent = e.target.value;
    });
    document.getElementById('pg-topk')?.addEventListener('input', (e) => {
      document.getElementById('pg-topk-val').textContent = e.target.value;
    });

    // Quiz
    document.getElementById('start-quiz-btn')?.addEventListener('click', startQuiz);
  }

  /* =================== Pipeline =================== */

  function runPipeline() {
    const input = document.getElementById('pipeline-input');
    const text = input?.value?.trim();
    if (!text) return;

    const result = LLMEngine.simulatePipeline(text);
    const container = document.getElementById('pipeline-container');
    if (!container) return;

    let html = '';

    result.stages.forEach((stage, idx) => {
      html += `<div class="card-flat mb-4 pipeline-stage" style="animation: fadeSlideIn 0.4s ease ${idx * 0.15}s both;">`;
      html += `<div class="flex items-center gap-3 mb-4">
        <span style="font-size:1.8rem;">${stage.icon}</span>
        <div>
          <h4 style="margin:0;">${stage.name}</h4>
          <p class="text-sm text-muted" style="margin:0;">${stage.desc}</p>
        </div>
      </div>`;

      if (idx === 0) {
        // Tokenization
        html += `<div class="flex flex-wrap gap-2">
          ${stage.data.map(d => `
            <div class="token-chip" style="--chip-color: var(--primary);">
              <span>${d.token}</span>
              <span class="text-xs" style="opacity:0.7;">ID: ${d.id}</span>
            </div>
          `).join('')}
        </div>`;

      } else if (idx === 1) {
        // Embeddings + Position
        html += `<div style="overflow-x:auto;"><table class="attn-step-table">
          <thead><tr><th>Token</th><th>Embedding (4D)</th><th>Pos. Encoding</th></tr></thead><tbody>`;
        stage.data.forEach(d => {
          html += `<tr>
            <td class="font-bold">${d.token}</td>
            <td class="font-mono text-xs">[${d.vec.map(v => v.toFixed(3)).join(', ')}]</td>
            <td class="font-mono text-xs">[${d.posEnc.map(v => v.toFixed(3)).join(', ')}]</td>
          </tr>`;
        });
        html += `</tbody></table></div>`;

      } else if (idx === 2) {
        // Transformer blocks
        html += `<div class="llm-layers-grid">
          ${stage.data.map(layer => `
            <div class="llm-layer-card">
              <span class="text-xs font-bold text-primary">Layer ${layer.layer}</span>
              <div class="llm-layer-ops">
                ${layer.operations.map(op => `<span class="llm-op-badge">${op}</span>`).join('')}
              </div>
            </div>
          `).join('')}
        </div>`;

      } else if (idx === 3) {
        // Predictions
        html += `<div class="flex flex-col gap-2">
          ${stage.data.slice(0, 8).map((c, i) => {
            const pct = (c.prob * 100).toFixed(1);
            const isTop = i === 0;
            return `
            <div class="flex items-center gap-3">
              <span class="font-bold ${isTop ? 'text-accent' : ''}" style="width:80px;">
                ${isTop ? '‚≠ê ' : ''}${c.word}
              </span>
              <div class="progress-bar" style="flex:1;height:${isTop ? 14 : 10}px;">
                <div class="progress-fill" style="width:${pct}%;background:${isTop ? 'var(--accent)' : 'var(--primary)'};"></div>
              </div>
              <span class="text-sm font-mono" style="width:55px;">${pct}%</span>
            </div>`;
          }).join('')}
        </div>`;
      }

      html += `</div>`;
    });

    container.innerHTML = html;
  }

  /* =================== Generation =================== */

  function runGeneration() {
    const input = document.getElementById('gen-input');
    const countInput = document.getElementById('gen-count');
    const text = input?.value?.trim();
    if (!text) return;

    const maxTokens = parseInt(countInput?.value) || 6;
    const result = LLMEngine.generateSequence(text, maxTokens, 0.8, 5);

    // Show output being "typed"
    const outputEl = document.getElementById('gen-output');
    const stepsEl = document.getElementById('gen-steps');
    const stopBtn = document.getElementById('gen-stop-btn');
    const runBtn = document.getElementById('gen-run-btn');
    if (!outputEl || !stepsEl) return;

    runBtn.disabled = true;
    stopBtn.disabled = false;
    stepsEl.innerHTML = '';

    const promptWords = text.split(/\s+/);
    outputEl.innerHTML = `
      <div class="card-flat">
        <div class="gen-text" id="gen-text">
          <span class="gen-prompt">${promptWords.join(' ')}</span>
          <span class="gen-cursor">‚ñä</span>
        </div>
      </div>
    `;

    let step = 0;
    generationInterval = setInterval(() => {
      if (step >= result.steps.length) {
        stopGeneration();
        return;
      }

      const s = result.steps[step];
      const textEl = document.getElementById('gen-text');
      if (textEl) {
        // Remove cursor, add word, re-add cursor
        const cursor = textEl.querySelector('.gen-cursor');
        const wordSpan = document.createElement('span');
        wordSpan.className = 'gen-word';
        wordSpan.textContent = ' ' + s.chosen;
        wordSpan.style.animation = 'fadeIn 0.3s ease';
        textEl.insertBefore(wordSpan, cursor);
      }

      // Add step card
      const stepCard = document.createElement('div');
      stepCard.className = 'card-flat mb-3';
      stepCard.style.animation = 'fadeSlideIn 0.3s ease both';
      stepCard.innerHTML = `
        <div class="flex items-center justify-between mb-2">
          <span class="badge badge-primary">Passo ${s.step}</span>
          <span class="text-xs text-muted">Contexto: "...${s.context.slice(-3).join(' ')}"</span>
        </div>
        <div class="flex flex-wrap gap-2">
          ${s.candidates.map(c => `
            <span class="token-chip ${c.word === s.chosen ? 'chosen' : ''}" 
              style="--chip-color: ${c.word === s.chosen ? 'var(--accent)' : 'var(--primary)'};">
              ${c.word} <span class="text-xs" style="opacity:0.7;">${(c.prob * 100).toFixed(0)}%</span>
            </span>
          `).join('')}
        </div>
      `;
      stepsEl.appendChild(stepCard);

      step++;
    }, 600);
  }

  function stopGeneration() {
    if (generationInterval) {
      clearInterval(generationInterval);
      generationInterval = null;
    }
    const cursor = document.querySelector('.gen-cursor');
    if (cursor) cursor.remove();
    const runBtn = document.getElementById('gen-run-btn');
    const stopBtn = document.getElementById('gen-stop-btn');
    if (runBtn) runBtn.disabled = false;
    if (stopBtn) stopBtn.disabled = true;
  }

  /* =================== AI Real Generation =================== */
  async function runAIGeneration() {
    const input = document.getElementById('gen-input');
    const text = input?.value?.trim();
    if (!text) return;

    if (!FoundryService.isConfigured()) {
      Toast.show('Configure a API em ‚öôÔ∏è Configura√ß√µes primeiro.', 'error');
      return;
    }

    const outputEl = document.getElementById('gen-output');
    const stepsEl = document.getElementById('gen-steps');
    if (!outputEl) return;

    const aiBtn = document.getElementById('gen-ai-btn');
    if (aiBtn) { aiBtn.disabled = true; aiBtn.textContent = '‚è≥ Gerando...'; }

    outputEl.innerHTML = `
      <div class="card-flat config-test-loading">
        <div class="spinner"></div>
        <span>Enviando prompt para o modelo real...</span>
      </div>`;
    if (stepsEl) stepsEl.innerHTML = '';

    try {
      const systemPrompt = `Voc√™ √© um assistente que continua textos. O usu√°rio vai fornecer o in√≠cio de um texto e voc√™ deve continuar de forma natural e coerente. Continue o texto diretamente, sem explica√ß√µes. M√°ximo 150 palavras.`;
      const result = await FoundryService.chatCompletion([
        { role: 'system', content: systemPrompt },
        { role: 'user', content: `Continue este texto: "${text}"` },
      ], { maxTokens: 200 });

      outputEl.innerHTML = `
        <div class="card-flat" style="border-color:#0078d444;">
          <div class="flex items-center justify-between mb-3">
            <span class="ai-badge">‚ö° IA Real ‚Äî ${result.model}</span>
            <span class="text-xs text-muted">‚è±Ô∏è ${result.elapsed}ms${result.usage?.total_tokens ? ' ¬∑ ' + result.usage.total_tokens + ' tokens' : ''}</span>
          </div>
          <div class="gen-text">
            <span class="gen-prompt">${escapeHtml(text)}</span>
            <span class="gen-word" style="color:var(--accent);"> ${escapeHtml(result.content)}</span>
          </div>
        </div>`;
    } catch (err) {
      outputEl.innerHTML = `
        <div class="card-flat config-test-error">
          <strong style="color:#ef4444;">‚ùå Erro:</strong>
          <p class="text-sm mt-2">${escapeHtml(err.message)}</p>
        </div>`;
    } finally {
      if (aiBtn) { aiBtn.disabled = false; aiBtn.textContent = '‚ö° Gerar com IA Real'; }
    }
  }

  function escapeHtml(str) {
    return (str || '').replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;');
  }

  /* =================== Playground =================== */

  function updatePlayground() {
    const word = document.getElementById('pg-word')?.value?.trim() || 'the';
    const temp = parseFloat(document.getElementById('pg-temp')?.value) || 1.0;
    const topK = parseInt(document.getElementById('pg-topk')?.value) || 5;

    const { candidates } = LLMEngine.getNextWordProbs(word);
    const words = candidates.map(c => c.word);
    const probs = candidates.map(c => c.prob);

    const filtered = LLMEngine.topKFilter(words, probs, topK);

    // Apply temperature
    const tempProbs = filtered.map(f => Math.pow(f.prob, 1 / temp));
    const tempSum = tempProbs.reduce((s, v) => s + v, 0);
    const finalProbs = tempProbs.map(v => v / tempSum);

    const chart = document.getElementById('pg-chart');
    if (!chart) return;

    const maxProb = Math.max(...finalProbs);

    chart.innerHTML = `
      <div class="flex flex-col gap-3">
        ${filtered.map((f, i) => {
          const pct = (finalProbs[i] * 100).toFixed(1);
          const origPct = (f.prob * 100).toFixed(1);
          const barW = (finalProbs[i] / maxProb) * 100;
          return `
          <div class="flex items-center gap-3">
            <span class="font-bold text-sm" style="width:70px;">${f.word}</span>
            <div class="progress-bar" style="flex:1;height:12px;">
              <div class="progress-fill" style="width:${barW}%;background:var(--primary);transition:width 0.4s ease;"></div>
            </div>
            <span class="text-xs font-mono" style="width:50px;">${pct}%</span>
          </div>`;
        }).join('')}
      </div>
      <div class="mt-4 text-xs text-muted">
        <p>üå°Ô∏è Temp ${temp}: ${temp < 0.5 ? 'distribui√ß√£o concentrada (greedy)' : temp < 1.2 ? 'distribui√ß√£o balanceada' : 'distribui√ß√£o achatada (aleat√≥ria)'}.</p>
        <p>üéØ Top-${topK}: ${topK <= 2 ? 'pouqu√≠ssimas op√ß√µes' : topK <= 5 ? 'op√ß√µes moderadas' : 'muitas op√ß√µes'}.</p>
      </div>
    `;
  }

  /* =================== Quiz Logic =================== */

  function startQuiz() {
    quizState = { current: 0, answers: [], startTime: Date.now() };
    document.getElementById('start-quiz-btn')?.closest('.card-flat')?.classList.add('hidden');
    document.getElementById('quiz-container')?.classList.remove('hidden');
    document.getElementById('quiz-results')?.classList.add('hidden');
    renderQuizQuestion();
  }

  function renderQuizQuestion() {
    const container = document.getElementById('quiz-container');
    if (!container) return;
    const q = QUIZ_QUESTIONS[quizState.current];
    const num = quizState.current + 1;
    const total = QUIZ_QUESTIONS.length;

    container.innerHTML = `
      <div class="card-flat quiz-card">
        <div class="flex items-center justify-between mb-4">
          <span class="badge badge-primary">Pergunta ${num}/${total}</span>
          <div class="progress-bar" style="width: 200px;">
            <div class="progress-fill" style="width: ${(num / total) * 100}%"></div>
          </div>
        </div>
        <h3 class="mb-8">${q.question}</h3>
        <div class="quiz-options">
          ${q.options.map((opt, i) => `
            <button class="quiz-option" data-index="${i}">
              <span class="quiz-option-letter">${String.fromCharCode(65 + i)}</span>
              <span>${opt}</span>
            </button>
          `).join('')}
        </div>
      </div>
    `;

    container.querySelectorAll('.quiz-option').forEach(btn => {
      btn.addEventListener('click', () => handleQuizAnswer(parseInt(btn.dataset.index)));
    });
  }

  function handleQuizAnswer(idx) {
    const q = QUIZ_QUESTIONS[quizState.current];
    const isCorrect = idx === q.correct;
    quizState.answers.push({ selected: idx, correct: q.correct, isCorrect });

    const container = document.getElementById('quiz-container');
    const options = container.querySelectorAll('.quiz-option');
    options.forEach((opt, i) => {
      opt.style.pointerEvents = 'none';
      if (i === q.correct) opt.classList.add('quiz-correct');
      else if (i === idx && !isCorrect) opt.classList.add('quiz-wrong');
    });

    const card = container.querySelector('.quiz-card');
    const expl = document.createElement('div');
    expl.className = `quiz-explanation ${isCorrect ? 'correct' : 'wrong'} mt-4`;
    expl.innerHTML = `
      <p><strong>${isCorrect ? '‚úÖ Correto!' : '‚ùå Incorreto!'}</strong></p>
      <p class="text-sm">${q.explanation}</p>
      <button class="btn btn-primary mt-4 quiz-next-btn">
        ${quizState.current < QUIZ_QUESTIONS.length - 1 ? 'Pr√≥xima ‚Üí' : 'Ver Resultado'}
      </button>
    `;
    card.appendChild(expl);

    expl.querySelector('.quiz-next-btn').addEventListener('click', () => {
      quizState.current++;
      if (quizState.current < QUIZ_QUESTIONS.length) renderQuizQuestion();
      else finishQuiz();
    });
  }

  function finishQuiz() {
    const score = quizState.answers.filter(a => a.isCorrect).length;
    const total = QUIZ_QUESTIONS.length;
    const elapsed = Math.round((Date.now() - quizState.startTime) / 1000);
    const result = Progress.completeQuiz('llm', score, total);

    document.getElementById('quiz-container')?.classList.add('hidden');
    const results = document.getElementById('quiz-results');
    if (!results) return;
    results.classList.remove('hidden');

    const pct = Math.round((score / total) * 100);
    const msg = pct >= 100 ? 'üèÜ Perfeito!' : pct >= 70 ? 'üéâ Muito bom!' : pct >= 40 ? 'üëç Bom come√ßo!' : 'üìö Continue estudando!';

    results.innerHTML = `
      <div class="card-flat text-center">
        <h2>${msg}</h2>
        <div class="module-stars mt-4 mb-4" style="font-size: 2.5rem;">
          ${[1, 2, 3].map(s => `<span class="star ${s <= result.stars ? 'earned' : ''}">‚òÖ</span>`).join('')}
        </div>
        <p class="text-lg">${score}/${total} corretas (${pct}%)</p>
        <p class="text-muted">Tempo: ${elapsed}s</p>
        <p class="text-muted text-sm mt-4">+${score * 10 + result.stars * 15} XP ganhos!</p>
        <div class="flex justify-center gap-4 mt-8">
          <button class="btn btn-secondary" onclick="location.reload()">üîÑ Tentar novamente</button>
          <a href="#/" class="btn btn-primary">‚Üê Voltar √† trilha</a>
        </div>
      </div>
    `;

    if (elapsed < 60 && score >= 4) Achievements.unlock('speedrunner');
    Achievements.checkAll();
  }

  return { render, initInteractions };
})();
